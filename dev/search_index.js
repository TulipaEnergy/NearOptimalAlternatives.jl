var documenterSearchIndex = {"docs":
[{"location":"10-how-to-use/","page":"How to use","title":"How to use","text":"Pages = [\"how-to-use.md\"]\nDepth = 5","category":"section"},{"location":"10-how-to-use/#How-to-use","page":"How to use","title":"How to use","text":"This section gives an introduction to the package installation, main functions, and their inputs and outputs.","category":"section"},{"location":"10-how-to-use/#Install","page":"How to use","title":"Install","text":"In Julia:\n\nEnter package mode (press \"]\")\n\npkg> add NearOptimalAlternatives\n\nReturn to Julia mode (backspace)\n\njulia> using NearOptimalAlternatives","category":"section"},{"location":"10-how-to-use/#Main-functions","page":"How to use","title":"Main functions","text":"To generate alternative solutions to a solved JuMP model, use either of the functions:\n\ngenerate_alternatives_optimization!(model, optimality_gap, n_alternatives)\ngenerate_alternatives_metaheuristics(model, optimality_gap, n_alternatives, metaheuristic_algorithm)\n\nThe model should be a solved JuMP model. The optimality_gap is the maximum percentage of deviation from the optimal solution. n_alternatives specifies the desired number of alternative solutions. If you want to generate alternatives with a metaheuristic instead of mathematical optimization, use generate_alternatives_metaheuristics instead of generate_alternatives_optimization! and specify the metaheuristic_algorithm to use. Other optional input parameters are specified in the Input section below.","category":"section"},{"location":"10-how-to-use/#Input","page":"How to use","title":"Input","text":"The following parameters can be supplied to either of the alternative generating functions (unless otherwise specified). The ones alreay mentioned in the previous section are required, the rest is optional.\n\nmodel: The solved JuMP model for which we want to find alternative solutions. When using optimization to find alternatives, the solver specified to solve this model will also perform the optimization for finding alternatives.\noptimality_gap: The maximum objective value deviation each of the alternative solutions may have from the original solution. An optimality gap of 0.5 means that the objective value of an alternative solution must be at least 50% of the optimal objective value found by solving model (in case of a maximization problem).\nn_alternatives: The number of alternative solutions to be found by this package.\nmetaheuristic_algorithm (only for generate_alternatives_metaheuristics): The algorithm used to find alternative solutions. Can be an algorithm from Metaheuristics.jl or the algorithm we developed: PSOGA. The former are repeated iteratively to find multiple alternatives, the latter generates multiple alternatives concurrently.\nmetric: The distance metric used to compute the difference between solutions (between different alternatives and between alternatives and the optimal solution). This metric should be a SemiMetric from the Distances.jl package. Note that, depending on the solver used, several metrics might not be usable when finding alternatives using optimization. When using a metaheuristic, any metric is usable.\nfixed_variables: A vector of variables that should remain fixed when finding alternative solutions. One can use this to find near optimal alternative solutions that only modify a subset of all variables and leave the rest unchanged.","category":"section"},{"location":"10-how-to-use/#Output","page":"How to use","title":"Output","text":"Both methods for generating alternative solutions return the results in the same form: a structure AlternativeSolutions containing a vector solutions and objective_values.\n\nsolutions holds a dictionary containing the solution value for every JuMP variables (based on its VariableRef), per alternative solution.\nobjective_values is a vector of floats representing the objective value of each of the alternative solutions.","category":"section"},{"location":"30-concepts/","page":"Concepts","title":"Concepts","text":"Pages = [\"concepts.md\"]\nDepth = 5","category":"section"},{"location":"30-concepts/#Concepts","page":"Concepts","title":"Concepts","text":"Here we explain in more detail the underlying theoretical concepts of NearOptimalAlternatives.jl. We first discuss the optimization-based approaches and then discuss the evolutionary approaches.","category":"section"},{"location":"30-concepts/#Optimization-based-Methods","page":"Concepts","title":"Optimization-based Methods","text":"One can directly maximize the distance among the alternatives or minimized the weighted sum of decision variables using a variety of methods listed below.","category":"section"},{"location":"30-concepts/#Max-Distance-(:Max_Distance)","page":"Concepts","title":"Max-Distance (:Max_Distance)","text":"Files: MGA-Methods/Max-Distance.jl\nGoal: maximize distance between the current solution and the reference solution using a chosen metric (default: squared Euclidean; updates default to Cityblock).\nBehavior: Dist_initial! fixes specified variables, captures the current solution, and sets a distance-maximizing objective. Dist_update! adds additional distance terms to encourage further diversity across iterations.\n\nGiven the optimal solution x^*, we solve the following problem for any distance metric d.\n\ntextMaximize  x - x^* _d ","category":"section"},{"location":"30-concepts/#Hop-Skip-Jump-(:HSJ)","page":"Concepts","title":"Hop-Skip-Jump (:HSJ)","text":"Files: MGA-Methods/HSJ.jl\nGoal: minimize a weighted sum where weights are 1 for nonzero variables and 0 otherwise, biasing the search away from the current support.\nBehavior: HSJ_initial! fixes requested variables and sets weights from the current solution; HSJ_update! recomputes weights from the latest solution before re-solving.\nHop-Skip-Jump (HSJ) [HSJ1982] is a method that tries to find alternatives by minimizing the variables that had a non-zero value in the previous iteration. This is done to find alternatives that invest less in the decision variable, which was already invested in in the previous iteration. More precisely, it minimizes based on the value of the variables in the previous iteration.\n\nThe objective is to minimize the weighted sum of decision variables x_i using weights w_i^k where i is the index of variables and k is the index of iterations.\n\nw_i^k = begincases\n0  textif  x_i^k-1 = 0 \n1  textotherwise\nendcases","category":"section"},{"location":"30-concepts/#Spores-(:Spores)","page":"Concepts","title":"Spores (:Spores)","text":"Files: MGA-Methods/Spores.jl\nGoal: shift emphasis toward variables that could take larger values relative to their upper bounds (upper bounds required for all variables involved).\nBehavior: Spores_initial! and Spores_update! accumulate weights as weights[i] += value(v) / upper_bound(v) and minimize the resulting weighted sum.\nSpores [SPORES2020] is a modification of HSJ. It does not discard the weights of the previous iteration. Instead, it updates them using the update rule as described below. This equation introduces x^max_i , which refers to the maximum possible value that x_i can take. This update rule assigns a high weight to variables whose value is close to the maximum value, while assigning a low weight to variables whose value is close to zero. This is similar to the HSJ method, but with the ability to be more expressive.\n\nThe objective is to minimize the weighted sum of decision variables x_i using weights w_i^k where i is the index of variables and k is the index of iterations.\n\nw_i^k = w_i^k-1 + fracx_i^k-1x_i^textmax quad forall k 1 leq k leq n\n\nw_i^0 = 0","category":"section"},{"location":"30-concepts/#Min/Max-Variables-(:Min_Max_Variables)","page":"Concepts","title":"Min/Max Variables (:Min_Max_Variables)","text":"Files: MGA-Methods/Min-Max-Variables.jl\nGoal: randomly push variables to be minimized, maximized, or ignored to explore diverse corners of the feasible region.\nBehavior: both *_initial! and *_update! draw weights uniformly from {-1, 0, 1} and minimize the weighted sum.\nMin/Max Variables [Evelina2012][Lukas2019] is an approach that minimizes and/or maximizes a random sample of variables. This is done by randomly sampling the weights as specified below. Contrary to HSJ and Spores, the Min/Max Variables does not consider any previously found alternatives. When applying this approach, all variables with weight 1 get minimized, the variable with weight −1 gets maximized, and the variables with weight 0 are free.\n\nThe objective is to minimize the weighted sum of decision variables x_i using weights w_i^k where i is the index of variables and k is the index of iterations.\n\nw_i sim textUniform(1 0 1) forall i","category":"section"},{"location":"30-concepts/#Random-Vector-(:Random_Vector)","page":"Concepts","title":"Random Vector (:Random_Vector)","text":"Files: MGA-Methods/Random-Vector.jl\nGoal: similar to Min/Max Variables but with continuous random weights in [-1, 1] for smoother perturbations.\nBehavior: each call redraws weights from Uniform(-1, 1) and minimizes the weighted sum.\nRandom Vector [RANDV2017] is similar to Min/Max Variables. Where Min/Max Variables samples either −1, 0, or 1, Random Vector samples a predefined distribution for all variables, most of the time this distribution is the uniform distribution between −1 and 1, as described below. However, the distribution can be different for each variable to best fit the model being solved.\n\nThe objective is to minimize the weighted sum of decision variables x_i using weights w_i^k where i is the index of variables and k is the index of iterations.\n\nw_i sim textUniform(1 1) forall i","category":"section"},{"location":"30-concepts/#Directionally-Weighted-Variables-(:Directionally_Weighted_Variables)","page":"Concepts","title":"Directionally Weighted Variables (:Directionally_Weighted_Variables)","text":"Files: MGA-Methods/Directionally-Weighted-Variables.jl\nGoal: choose variable directions based on the sign of their coefficients in the original objective to promote directional diversity. This helps to find non-dominated solutions. For the concept of dominance, check out [VandeLaar2025].\nBehavior: weights depend on objective coefficients (>0 draws from {0,1}, <0 from {-1,0}, else {-1,0,1}); DWV_initial! fixes requested variables, sets the weighted-sum objective, and DWV_update! redraws weights before the next solve.","category":"section"},{"location":"30-concepts/#Evolutionary-Methods","page":"Concepts","title":"Evolutionary Methods","text":"Evolutionary algorithms have been proposed as an alternative method to mathematical programming for generating alternative solutions by Zechman and Ranjithan [Zechman].\n\nTheir method works as follows. Instead of simply initializing an initial population as a regular evolutionary algorithm would do, they divide this population into P subpopulations, where P is equal to the number of alternative solutions to be found. Each subpopulation is dedicated to search for one alternative solution. The first subpopulation can also be used to find the global optimum. After initializing the population, they take the following steps iteratively. First, evaluate all individuals with respect to the objective and feasibility. Also, the distance between this solution and other subpopulations, or there centroids, is taken into account. So, the best individual is a feasible solution which is furthest away from other subpopulations. They used elitism to preserve the best solution in each subpopulation. Afterwards, after checking stopping criteria, they applied binary tournament selection based on the fitness of the solution to select the rest of the individuals.","category":"section"},{"location":"30-concepts/#Particle-Swarm-Optimization-for-Generating-Alternatives-(PSOGA)","page":"Concepts","title":"Particle Swarm Optimization for Generating Alternatives (PSOGA)","text":"In this package we developed PSOGA, an modification of Evolutionary Algorithms for Generating Alternatives using Particle Swarm Optimization (PSO).\n\nFiles: algorithms/PSOGA/PSOGA.jl and algorithms/PSOGA/is_better.jl.\nGoal: maximize distance from provided solution within search space\nBehavior: initialize! initializez population and global parameters. update_state! performs one loop of he metaheuristic process. final_stage! performs final steps after solving the problem.\n\nIt works as follows.\n\nWhen initializing the algorithm, the population of individuals is divided into n equal-size subpopulations, where n is the number of alternative solutions sought. As with regular PSO, each individual has a position x and a velocity v.\n\nThe update step of the algorithm works very similar to regular PSO. In every iteration, each individual is updated as follows. First, its velocity is updated and becomes v = omega cdot v + textitrand(01) cdot c_1 cdot (p_textitbest - x)  + textitrand(01) cdot c_2 cdot (s_textitbest - x) In the above equation, omega represents the inertia, c_1 is the cognitive parameter and c_2 is the social parameter. These make sure that the old velocity is taken into account, previous information from this individual is used and information from other individuals in the subpopulation is used, respectively. Therefore, the variables p_textitbest, representing the personal best position of this individual, and s_textitbest,representing the alltime best of the subpopulation this individual is in, are required. Note that s_textitbest replaces g_textitbest, which is used in regular PSO and represents the global best solution of the full population.\n\nAfter updating the velocity of each individual, all positions are updated using x = x + v. Subsequently, all personal bests and subpopulation bests are updated based on the objective value. For PSOGA the objective is to generate alternatives that are as different as possible from the optimal solution, but also from each other. The aim here is to make sure each subpopulation finds one alternative, and these are spread out over the search space.\n\nWhen comparing two solutions to decide which is better, we therefore take the following approach. If either of the solutions is infeasible, we take the solution with the smallest constraint violation. If none are infeasible we pick the one with the largest distance, where the distance can be defined in two ways. Either, we calculate the sum of all distances to other subpopulations and to the original optimal solution, or we calculate the minimum of the distances to other subpopulations and the original optimal solution. To compute the distance to other subpopulations, we calculate the centroid (average) of all points in the subpopulation and compute the distance to that centroid.\n\nThe algorithm terminates when the subpopulations have converged, or the maximum number of iterations has been met. By then, the subpopulations should be spread out over the feasible space and as far as possible from the initial optimal solution.","category":"section"},{"location":"30-concepts/#References","page":"Concepts","title":"References","text":"[Evelina2012]: Evelina Trutnevyte et al. “Context-specific energy strategies: coupling energy system visions with feasible implementation scenarios”. In: Environmental science & technology 46.17 (2012), pp. 9240–9248\n\n[HSJ1982]: E Downey Brill Jr, Shoou-Yuh Chang, and Lewis D Hopkins. “Modeling to generate alternatives: The HSJ approach and an illustration using a problem in land use planning”. In: Management Science 28.3 (1982), pp. 221–235.\n\n[Lukas2019]: Lukas Nacken et al. “Integrated renewable energy systems for Germany–A model-based exploration of the decision space”. In: 2019 16th international conference on the European energy market (EEM). IEEE. 2019, pp. 1–8.\n\n[RANDV2017]: Philip B Berntsen and Evelina Trutnevyte. “Ensuring diversity of national energy scenarios: Bottomup energy system model with Modeling to Generate Alternatives”. In: Energy 126 (2017), pp. 886–898.\n\n[SPORES2020]: Francesco Lombardi et al. “Policy decision support for renewables deployment through spatially explicit practically optimal alternatives”. In: Joule 4.10 (2020), pp. 2185–2207.\n\n[VandeLaar2025]: Luuk van de Laar. \"Dominance-Aware Generation of Near-Optimal Alternatives in Energy System Models\", TU Delft thesis, 2025\n\n[Zechman]: E. M. Zechman and S. R. Ranjithan, “An evolutionary algorithm to generate alternatives (eaga) for engineering optimization problems,” Engineering Optimization, vol. 36, no. 5, pp. 539–553, 2004.","category":"section"},{"location":"91-developer/#dev_docs","page":"Developer documentation","title":"Developer documentation","text":"note: Contributing guidelines\nIf you haven't, please read the Contributing guidelines first.\n\nIf you want to make contributions to this package that involves code, then this guide is for you.","category":"section"},{"location":"91-developer/#First-time-clone","page":"Developer documentation","title":"First time clone","text":"tip: If you have writing rights\nIf you have writing rights, you don't have to fork. Instead, simply clone and skip ahead. Whenever upstream is mentioned, use origin instead.\n\nIf this is the first time you work with this repository, follow the instructions below to clone the repository.\n\nFork this repo\nClone your repo (this will create a git remote called origin)\nAdd this repo as a remote:\ngit remote add upstream https://github.com/TulipaEnergy/NearOptimalAlternatives.jl\n\nThis will ensure that you have two remotes in your git: origin and upstream. You will create branches and push to origin, and you will fetch and update your local main branch from upstream.","category":"section"},{"location":"91-developer/#Linting-and-formatting","page":"Developer documentation","title":"Linting and formatting","text":"Install a plugin on your editor to use EditorConfig. This will ensure that your editor is configured with important formatting settings.\n\nWe use https://pre-commit.com to run the linters and formatters. In particular, the Julia code is formatted using JuliaFormatter.jl, so please install it globally first:\n\njulia> # Press ]\npkg> activate\npkg> add JuliaFormatter\n\nTo install pre-commit, we recommend using pipx as follows:\n\n# Install pipx following the link\npipx install pre-commit\n\nWith pre-commit installed, activate it as a pre-commit hook:\n\npre-commit install\n\nTo run the linting and formatting manually, enter the command below:\n\npre-commit run -a\n\nNow, you can only commit if all the pre-commit tests pass.","category":"section"},{"location":"91-developer/#Testing","page":"Developer documentation","title":"Testing","text":"As with most Julia packages, you can just open Julia in the repository folder, activate the environment, and run test:\n\njulia> # press ]\npkg> activate .\npkg> test","category":"section"},{"location":"91-developer/#Working-on-a-new-issue","page":"Developer documentation","title":"Working on a new issue","text":"We try to keep a linear history in this repo, so it is important to keep your branches up-to-date.\n\nFetch from the remote and fast-forward your local main\ngit fetch upstream\ngit switch main\ngit merge --ff-only upstream/main\nBranch from main to address the issue (see below for naming)\ngit switch -c 42-add-answer-universe\nPush the new local branch to your personal remote repository\ngit push -u origin 42-add-answer-universe\nCreate a pull request to merge your remote branch into the org main.","category":"section"},{"location":"91-developer/#Branch-naming","page":"Developer documentation","title":"Branch naming","text":"If there is an associated issue, add the issue number.\nIf there is no associated issue, and the changes are small, add a prefix such as \"typo\", \"hotfix\", \"small-refactor\", according to the type of update.\nIf the changes are not small and there is no associated issue, then create the issue first, so we can properly discuss the changes.\nUse dash separated imperative wording related to the issue (e.g., 14-add-tests, 15-fix-model, 16-remove-obsolete-files).","category":"section"},{"location":"91-developer/#Commit-message","page":"Developer documentation","title":"Commit message","text":"Use imperative or present tense, for instance: Add feature or Fix bug.\nHave informative titles.\nWhen necessary, add a body with details.\nIf there are breaking changes, add the information to the commit message.","category":"section"},{"location":"91-developer/#Before-creating-a-pull-request","page":"Developer documentation","title":"Before creating a pull request","text":"tip: Atomic git commits\nTry to create \"atomic git commits\" (recommended reading: The Utopic Git History).\n\nMake sure the tests pass.\nMake sure the pre-commit tests pass.\nFetch any main updates from upstream and rebase your branch, if necessary:\ngit fetch upstream\ngit rebase upstream/main BRANCH_NAME\nThen you can open a pull request and work with the reviewer to address any issues.","category":"section"},{"location":"91-developer/#Building-and-viewing-the-documentation-locally","page":"Developer documentation","title":"Building and viewing the documentation locally","text":"Following the latest suggestions, we recommend using LiveServer to build the documentation. Here is how you do it:\n\nRun julia --project=docs to open Julia in the environment of the docs.\nIf this is the first time building the docs\nPress ] to enter pkg mode\nRun pkg> dev . to use the development version of your package\nPress backspace to leave pkg mode\nRun julia> using LiveServer\nRun julia> servedocs()","category":"section"},{"location":"91-developer/#Making-a-new-release","page":"Developer documentation","title":"Making a new release","text":"To create a new release, you can follow these simple steps:\n\nCreate a branch release-x.y.z\nUpdate version in Project.toml\nUpdate the CHANGELOG.md:\nRename the section \"Unreleased\" to \"[x.y.z] - yyyy-mm-dd\" (i.e., version under brackets, dash, and date in ISO format)\nAdd a new section on top of it named \"Unreleased\"\nAdd a new link in the bottom for version \"x.y.z\"\nChange the \"[unreleased]\" link to use the latest version - end of line, vx.y.z ... HEAD.\nCreate a commit \"Release vx.y.z\", push, create a PR, wait for it to pass, merge the PR.\nGo back to main screen and click on the latest commit (link: https://github.com/TulipaEnergy/NearOptimalAlternatives.jl/commit/main)\nAt the bottom, write @JuliaRegistrator register\n\nAfter that, you only need to wait and verify:\n\nWait for the bot to comment (should take < 1m) with a link to a PR to the registry\nFollow the link and wait for a comment on the auto-merge\nThe comment should said all is well and auto-merge should occur shortly\nAfter the merge happens, TagBot will trigger and create a new GitHub tag. Check on https://github.com/TulipaEnergy/NearOptimalAlternatives.jl/releases\nAfter the release is create, a \"docs\" GitHub action will start for the tag.\nAfter it passes, a deploy action will run.\nAfter that runs, the stable docs should be updated. Check them and look for the version number.","category":"section"},{"location":"95-reference/#reference","page":"Reference","title":"Reference","text":"","category":"section"},{"location":"95-reference/#Contents","page":"Reference","title":"Contents","text":"Pages = [\"95-reference.md\"]","category":"section"},{"location":"95-reference/#Index","page":"Reference","title":"Index","text":"Pages = [\"95-reference.md\"]","category":"section"},{"location":"95-reference/#NearOptimalAlternatives.METHOD_DISPATCH_UPDATE","page":"Reference","title":"NearOptimalAlternatives.METHOD_DISPATCH_UPDATE","text":"const METHODDISPATCH shows the mapping of method symbols to their corresponding update functions for the modelling-for-generating-alternatives problem. It is used to dynamically select the appropriate function based on the method specified in the `createalternativegeneratingproblem!` function.\n\n\n\n\n\n","category":"constant"},{"location":"95-reference/#NearOptimalAlternatives.AlternativeSolutions","page":"Reference","title":"NearOptimalAlternatives.AlternativeSolutions","text":"Structure holding the solutions for the near-optimal alternatives.\n\n\n\n\n\n","category":"type"},{"location":"95-reference/#NearOptimalAlternatives.MetaheuristicProblem","page":"Reference","title":"NearOptimalAlternatives.MetaheuristicProblem","text":"Structure representing a problem that can be solved by Metaheuristics.jl and the algorithm to solve it.\n\n\n\n\n\n","category":"type"},{"location":"95-reference/#NearOptimalAlternatives.PSOGA","page":"Reference","title":"NearOptimalAlternatives.PSOGA","text":"Structure holding all parameters for PSOGA (Particle Swarm optimization for Generating Alternatives).\n\n\n\n\n\n","category":"type"},{"location":"95-reference/#NearOptimalAlternatives.PSOGA-Tuple{}","page":"Reference","title":"NearOptimalAlternatives.PSOGA","text":"PSOGA(;\n    N = 100,\n    N_solutions = 1,\n    C1 = 2.0,\n    C2 = 2.0,\n    ω = 0.8,\n    v = Float64[],\n    flock == Metaheuristics.xf_indiv[],\n    subBest = Metaheuristics.xf_indiv[],\n    information = Information(),\n    options = Options(),\n)\n\nConstruct a PSOGA Metaheuristic algorithm.\n\nArguments\n\nN: total population size\nN_solutions::Int: number of solutions sought. This is the same as the number of subpopulations searching for a solution.\nC1::Float64: cognitive parameter. Used to compute velocity based on own best solution.\n`C2::Float64: social parameter. Used to compute velocity based on best solution in subpopulation.\nω::Float64: inertia parameter. Used to compute velocity to ensure not too large changes.\nv::Array{Float64}: array of velocities per individual.\nflock::Array: array of all current positions of each of the individuals.\nsubBest::Array: array of best solutions per subpopulation.\nmaximise_total::Bool: if true, we maximise the sum of distances between a point and all centroids of other subpopulations, else we maximise the minimum distance between a point and the centroids of other subpopulations.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#Metaheuristics.final_stage!-Tuple{Any, NearOptimalAlternatives.PSOGA, Metaheuristics.AbstractProblem, Metaheuristics.Information, Metaheuristics.Options, Vararg{Any}}","page":"Reference","title":"Metaheuristics.final_stage!","text":"final_stage(     status,     parameters::PSOGA,     problem,     information,     options,     args...;     kwargs...   )\n\nPerform concluding operations after solving a problem using PSOGA. Called by main loop of Metaheuristics.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#Metaheuristics.initialize!-Tuple{Any, NearOptimalAlternatives.PSOGA, Any, Any, Any, Vararg{Any}}","page":"Reference","title":"Metaheuristics.initialize!","text":"initialize!(     status,     parameters::PSOGA,     problem,     information,     options,     args...;     kwargs...   )\n\ninitialize all parameters used when solving a problem using PSOGA. Called by main loop of Metaheuristics.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#Metaheuristics.update_state!-Tuple{Any, NearOptimalAlternatives.PSOGA, Metaheuristics.AbstractProblem, Metaheuristics.Information, Metaheuristics.Options, Vararg{Any}}","page":"Reference","title":"Metaheuristics.update_state!","text":"update_state(     status,     parameters::PSOGA,     problem,     information,     options,     args...;     kwargs...   )\n\nPerform one iteration of PSOGA. Called by main loop of Metaheuristics.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#NearOptimalAlternatives.DWV_initial!-Union{Tuple{N}, Tuple{T}, Tuple{JuMP.Model, AbstractArray{T, N}, Vector{JuMP.VariableRef}}} where {T<:Union{JuMP.VariableRef, JuMP.AffExpr}, N}","page":"Reference","title":"NearOptimalAlternatives.DWV_initial!","text":"DWV_initial!(\n    model::JuMP.Model,\n    variables::AbstractArray{T,N},\n    fixed_variables::Vector{VariableRef};\n    weights::Vector{Float64} = zeros(length(variables)),\n    metric::Distances.SemiMetric = SqEuclidean(),\n    old_objective::AffExpr = JuMP.objective_function(model),\n) where {T<:Union{VariableRef,AffExpr},N}\n\nInitialize the objective of a JuMP model using the Directionally Weighted Variables method to generate alternative solutions. This function sets a new objective that minimizes the weighted sum of the decision variables, where weights are uniformly chosen between -1 and 1, based on the original objective function. Fixed variables are locked at their optimal values.\n\nArguments\n\nmodel::JuMP.Model: a solved JuMP model whose objective is to be redefined for alternative generation.\nvariables::AbstractArray{T,N}: the variables involved in the objective, typically a vector or matrix of VariableRefs or AffExprs.\nfixed_variables::Vector{VariableRef}: variables to be fixed at their current values to avoid changes in alternatives.\nweights::Vector{Float64}: optional vector of weights for each variable; will be internally overwritten based on variable values.\nmetric::Distances.SemiMetric: unused in this method (included for consistency with other alternative generation methods).\nold_objective::AffExpr: the original objective function of the model, used to determine variable weights.\n\nBehavior\n\nVariables are randomly minimized or maximized, based on the original objective function.\nFixed variables are frozen at their optimal values using fix(...).\nThe objective is set to minimize the weighted sum of the variables, encouraging sparsity or deviation from the original.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#NearOptimalAlternatives.DWV_update!-Union{Tuple{N}, Tuple{T}, Tuple{JuMP.Model, AbstractArray{T, N}}} where {T<:Union{JuMP.VariableRef, JuMP.AffExpr}, N}","page":"Reference","title":"NearOptimalAlternatives.DWV_update!","text":"DWV_update!(\n    model::JuMP.Model,\n    variables::AbstractArray{T,N},\n    weights::Vector{Float64}\n) where {T<:Union{VariableRef,AffExpr},N}\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#NearOptimalAlternatives.Dist_initial!-Union{Tuple{N}, Tuple{T}, Tuple{JuMP.Model, AbstractArray{T, N}, Vector{JuMP.VariableRef}}} where {T<:Union{JuMP.VariableRef, JuMP.AffExpr}, N}","page":"Reference","title":"NearOptimalAlternatives.Dist_initial!","text":"Dist_initial!(\n    model::JuMP.Model,\n    variables::AbstractArray{T,N},\n    fixed_variables::Vector{VariableRef};\n    weights::Vector{Float64} = zeros(length(variables)),\n    metric::Distances.SemiMetric = SqEuclidean(),\n) where {T<:Union{VariableRef,AffExpr},N}\n\nInitialize a JuMP model's objective to maximize the distance between the current solution and a reference solution, based on a specified metric.\n\nThis function is typically used in the context of generating diverse solutions (alternatives) to an optimization problem by first defining a distance-based objective that measures how different a new solution is from an existing (optimal) one.\n\nArguments\n\nmodel::JuMP.Model: a JuMP model that has been previously solved.\nvariables::AbstractArray{T,N}: the variables of the model to consider in the distance computation.\nfixed_variables::Vector{VariableRef}: a subset of all variables of model that are not allowed to be changed when seeking for alternatives.\nweights::Vector{Float64}: optional weights to influence the distance calculation (currently not used directly but reserved for extensions).\nmetric::Distances.SemiMetric: the distance metric used to compute dissimilarity (default is squared Euclidean distance).\n\nBehavior\n\nExtracts the current solution values of variables.\nSets the model's objective to maximize the distance between the current variable values and the solution.\nChanges the model's objective sense to Max.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#NearOptimalAlternatives.Dist_update!-Union{Tuple{N}, Tuple{T}, Tuple{JuMP.Model, AbstractArray{T, N}}} where {T<:Union{JuMP.VariableRef, JuMP.AffExpr}, N}","page":"Reference","title":"NearOptimalAlternatives.Dist_update!","text":"Dist_update!(\n    model::JuMP.Model,\n    variables::AbstractArray{T,N};\n    weights::Vector{Float64} = zeros(length(variables)),\n    metric::Distances.SemiMetric = Cityblock(),\n) where {T<:Union{VariableRef,AffExpr},N}\n\nUpdate a JuMP model's objective function to include an additional distance term for generating multiple diverse alternatives (as in Modeling to Generate Alternatives).\n\nThis function builds upon a previously defined objective by incrementally adding a distance term between the current solution and a new reference solution. It is typically used after Dist_initial! or a prior call to MGA_Dist_update!.\n\nArguments\n\nmodel::JuMP.Model: the JuMP model being updated to generate further alternatives.\nvariables::AbstractArray{T,N}: the variables to consider in the distance computation.\nweights::Vector{Float64}: optional weights for the distance metric (currently not directly used).\nmetric::Distances.SemiMetric: the distance metric used to compute dissimilarity (default is Cityblock distance).\n\nBehavior\n\nEvaluates the current objective function to retrieve the cumulative distance so far.\nComputes the distance between the current variable values and their previous optimal values.\nUpdates the objective function to maximize the sum of the cumulative and new distances.\nResets the model's objective sense to Max.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#NearOptimalAlternatives.HSJ_initial!-Union{Tuple{N}, Tuple{T}, Tuple{JuMP.Model, AbstractArray{T, N}, Vector{JuMP.VariableRef}}} where {T<:Union{JuMP.VariableRef, JuMP.AffExpr}, N}","page":"Reference","title":"NearOptimalAlternatives.HSJ_initial!","text":"HSJ_initial!(\n    model::JuMP.Model,\n    variables::AbstractArray{T,N},\n    fixed_variables::Vector{VariableRef};\n    weights::Vector{Float64} = zeros(length(variables)),\n    metric::Distances.SemiMetric = SqEuclidean(),\n) where {T<:Union{VariableRef,AffExpr}, N}\n\nInitialize the objective of a JuMP model using the HSJ (Hop-Skip-Jump) method to generate alternative solutions.\n\nThis function sets a new objective that minimizes the weighted sum of the decision variables, where weights are based on the sign (non-zero value) of the original optimal solution. Fixed variables are locked at their optimal values.\n\nArguments\n\nmodel::JuMP.Model: a solved JuMP model whose objective is to be redefined for alternative generation.\nvariables::AbstractArray{T,N}: the variables involved in the objective, typically a vector or matrix of VariableRefs or AffExprs.\nfixed_variables::Vector{VariableRef}: variables to be fixed at their current values to avoid changes in alternatives.\nweights::Vector{Float64}: optional vector of weights for each variable; will be internally overwritten based on variable values.\nmetric::Distances.SemiMetric: unused in this method (included for consistency with other alternative generation methods).\n\nBehavior\n\nVariables that are zero in the original solution receive weight 0; others receive weight 1.\nFixed variables are frozen at their optimal values using fix(...).\nThe objective is set to minimize the weighted sum of the variables, encouraging sparsity or deviation from the original.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#NearOptimalAlternatives.HSJ_update!-Union{Tuple{N}, Tuple{T}, Tuple{JuMP.Model, AbstractArray{T, N}}} where {T<:Union{JuMP.VariableRef, JuMP.AffExpr}, N}","page":"Reference","title":"NearOptimalAlternatives.HSJ_update!","text":"HSJ_update!(\n    model::JuMP.Model,\n    variables::AbstractArray{T,N};\n    weights::Vector{Float64} = zeros(length(variables)),\n    metric::Distances.SemiMetric = SqEuclidean(),\n) where {T<:Union{VariableRef,AffExpr}, N}\n\nUpdate the objective of a JuMP model using the HSJ method to generate the next alternative solution.\n\nThis function redefines the objective based on the current optimal solution of the model, using weights determined by the sign of each variable's value (non-zero implies weight 1).\n\nArguments\n\nmodel::JuMP.Model: the JuMP model to be updated.\nvariables::AbstractArray{T,N}: the decision variables involved in the updated objective.\nweights::Vector{Float64}: optional vector of weights; will be overwritten based on current variable values.\nmetric::Distances.SemiMetric: unused in this method (included for interface consistency).\n\nBehavior\n\nVariables with a zero value receive weight 0; all others receive weight 1.\nA new objective is set: minimize the weighted sum of the variables.\nThis function does not re-fix any variables; it is typically called iteratively after HSJ_initial!.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#NearOptimalAlternatives.Min_Max_Variables_initial!-Union{Tuple{N}, Tuple{T}, Tuple{JuMP.Model, AbstractArray{T, N}, Vector{JuMP.VariableRef}}} where {T<:Union{JuMP.VariableRef, JuMP.AffExpr}, N}","page":"Reference","title":"NearOptimalAlternatives.Min_Max_Variables_initial!","text":"Min_Max_Variables_initial!(\n    model::JuMP.Model,\n    variables::AbstractArray{T,N},\n    fixed_variables::Vector{VariableRef};\n    weights::Vector{Float64} = zeros(length(variables)),\n    metric::Distances.SemiMetric = SqEuclidean(),\n) where {T<:Union{VariableRef,AffExpr}, N}\n\nInitialize the objective of a JuMP model using the Min/Max Variables method to generate alternative solutions. This function sets a new objective that minimizes the weighted sum of the decision variables, where weights are randomized between -1, 0 and 1. Fixed variables are locked at their optimal values.\n\nArguments\n\nmodel::JuMP.Model: a solved JuMP model whose objective is to be redefined for alternative generation.\nvariables::AbstractArray{T,N}: the variables involved in the objective, typically a vector or matrix of VariableRefs or AffExprs.\nfixed_variables::Vector{VariableRef}: variables to be fixed at their current values to avoid changes in alternatives.\nweights::Vector{Float64}: optional vector of weights for each variable; will be internally overwritten based on variable values.\nmetric::Distances.SemiMetric: unused in this method (included for consistency with other alternative generation methods).\n\nBehavior\n\nVariables are randomly minimized or maximized.\nFixed variables are frozen at their optimal values using fix(...).\nThe objective is set to minimize the weighted sum of the variables, encouraging sparsity or deviation from the original.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#NearOptimalAlternatives.Min_Max_Variables_update!-Union{Tuple{N}, Tuple{T}, Tuple{JuMP.Model, AbstractArray{T, N}}} where {T<:Union{JuMP.VariableRef, JuMP.AffExpr}, N}","page":"Reference","title":"NearOptimalAlternatives.Min_Max_Variables_update!","text":"Min_Max_Variables_update!(\n    model::JuMP.Model,\n    variables::AbstractArray{T,N};\n    weights::Vector{Float64} = zeros(length(variables)),\n    metric::Distances.SemiMetric = SqEuclidean(),\n) where {T<:Union{VariableRef,AffExpr}, N}\n\nUpdate the objective of a JuMP model using the Min/Max Variables method to generate the next alternative solution. Update the weights randomly between -1, 0 and 1.\n\nArguments\n\nmodel::JuMP.Model: the JuMP model to be updated.\nvariables::AbstractArray{T,N}: the decision variables involved in the updated objective.\nweights::Vector{Float64}: optional vector of weights; will be overwritten based on current variable values.\nmetric::Distances.SemiMetric: unused in this method (included for interface consistency).\n\nBehavior\n\nVariables are randomly minimized or maximized.\nA new objective is set: minimize the weighted sum of the variables.\nThis function does not re-fix any variables; it is typically called iteratively after Min_Max_Variables_initial!.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#NearOptimalAlternatives.Random_Vector_initial!-Union{Tuple{N}, Tuple{T}, Tuple{JuMP.Model, AbstractArray{T, N}, Vector{JuMP.VariableRef}}} where {T<:Union{JuMP.VariableRef, JuMP.AffExpr}, N}","page":"Reference","title":"NearOptimalAlternatives.Random_Vector_initial!","text":"Random_Vector_initial!(\n    model::JuMP.Model,\n    variables::AbstractArray{T,N},\n    fixed_variables::Vector{VariableRef};\n    weights::Vector{Float64} = zeros(length(variables)),\n    metric::Distances.SemiMetric = SqEuclidean(),\n) where {T<:Union{VariableRef,AffExpr}, N}\n\nInitialize the objective of a JuMP model using the Min/Max Variables method to generate alternative solutions. This function sets a new objective that minimizes the weighted sum of the decision variables, where weights are uniformly chosen between -1 and 1. Fixed variables are locked at their optimal values.\n\nArguments\n\nmodel::JuMP.Model: a solved JuMP model whose objective is to be redefined for alternative generation.\nvariables::AbstractArray{T,N}: the variables involved in the objective, typically a vector or matrix of VariableRefs or AffExprs.\nfixed_variables::Vector{VariableRef}: variables to be fixed at their current values to avoid changes in alternatives.\nweights::Vector{Float64}: optional vector of weights for each variable; will be internally overwritten based on variable values.\nmetric::Distances.SemiMetric: unused in this method (included for consistency with other alternative generation methods).\n\nBehavior\n\nVariables are randomly minimized or maximized.\nFixed variables are frozen at their optimal values using fix(...).\nThe objective is set to minimize the weighted sum of the variables, encouraging sparsity or deviation from the original.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#NearOptimalAlternatives.Random_Vector_update!-Union{Tuple{N}, Tuple{T}, Tuple{JuMP.Model, AbstractArray{T, N}}} where {T<:Union{JuMP.VariableRef, JuMP.AffExpr}, N}","page":"Reference","title":"NearOptimalAlternatives.Random_Vector_update!","text":"Random_Vector_update!(\n    model::JuMP.Model,\n    variables::AbstractArray{T,N};\n    weights::Vector{Float64} = zeros(length(variables)),\n    metric::Distances.SemiMetric = SqEuclidean(),\n) where {T<:Union{VariableRef,AffExpr}, N}\n\nUpdate the objective of a JuMP model using the Min/Max Variables method to generate the next alternative solution. Update the weights uniformly chosen between -1 and 1.\n\nArguments\n\nmodel::JuMP.Model: the JuMP model to be updated.\nvariables::AbstractArray{T,N}: the decision variables involved in the updated objective.\nweights::Vector{Float64}: optional vector of weights; will be overwritten based on current variable values.\nmetric::Distances.SemiMetric: unused in this method (included for interface consistency).\n\nBehavior\n\nVariables are randomly minimized or maximized.\nA new objective is set: minimize the weighted sum of the variables.\nThis function does not re-fix any variables; it is typically called iteratively after Random_Vector_initial!.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#NearOptimalAlternatives.Spores_initial!-Union{Tuple{N}, Tuple{T}, Tuple{JuMP.Model, AbstractArray{T, N}, Vector{JuMP.VariableRef}}} where {T<:Union{JuMP.VariableRef, JuMP.AffExpr}, N}","page":"Reference","title":"NearOptimalAlternatives.Spores_initial!","text":"Spores_initial!(\n    model::JuMP.Model,\n    variables::AbstractArray{T,N},\n    fixed_variables::Vector{VariableRef};\n    weights::Vector{Float64} = zeros(length(variables)),\n    metric::Distances.SemiMetric = SqEuclidean(),\n) where {T<:Union{VariableRef,AffExpr}, N}\n\nInitialize the objective of a JuMP model using the Spores method to generate alternative solutions. This function sets a new objective that minimizes the weighted sum of the decision variables, where weights are based on the  variable value of the original optimal solution. Fixed variables are locked at their optimal values. For this method to work the upper bound of the variables must be set.\n\nArguments\n\nmodel::JuMP.Model: a solved JuMP model whose objective is to be redefined for alternative generation.\nvariables::AbstractArray{T,N}: the variables involved in the objective, typically a vector or matrix of VariableRefs or AffExprs.\nfixed_variables::Vector{VariableRef}: variables to be fixed at their current values to avoid changes in alternatives.\nweights::Vector{Float64}: optional vector of weights for each variable; will be internally overwritten based on variable values.\nmetric::Distances.SemiMetric: unused in this method (included for consistency with other alternative generation methods).\n\nBehavior\n\nVariables are updated based on the potential value that they could have had.\nFixed variables are frozen at their optimal values using fix(...).\nThe objective is set to minimize the weighted sum of the variables, encouraging sparsity or deviation from the original.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#NearOptimalAlternatives.Spores_update!-Union{Tuple{N}, Tuple{T}, Tuple{JuMP.Model, AbstractArray{T, N}}} where {T<:Union{JuMP.VariableRef, JuMP.AffExpr}, N}","page":"Reference","title":"NearOptimalAlternatives.Spores_update!","text":"Spores_update!(\n    model::JuMP.Model,\n    variables::AbstractArray{T,N};\n    weights::Vector{Float64} = zeros(length(variables)),\n    metric::Distances.SemiMetric = SqEuclidean(),\n) where {T<:Union{VariableRef,AffExpr}, N}\n\nUpdate the objective of a JuMP model using the Spores method to generate the next alternative solution. This function redefines the objective based on the current optimal solution of the model, updating the weights with respect to the current variable values.\n\nArguments\n\nmodel::JuMP.Model: the JuMP model to be updated.\nvariables::AbstractArray{T,N}: the decision variables involved in the updated objective.\nweights::Vector{Float64}: optional vector of weights; will be overwritten based on current variable values.\nmetric::Distances.SemiMetric: unused in this method (included for interface consistency).\n\nBehavior\n\nVariables with are updated based on the previously optimal solution.\nA new objective is set: minimize the weighted sum of the variables.\nThis function does not re-fix any variables; it is typically called iteratively after Spores_initial!.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#NearOptimalAlternatives.add_solution!-Tuple{NearOptimalAlternatives.MetaheuristicProblem, Metaheuristics.State, Distances.SemiMetric}","page":"Reference","title":"NearOptimalAlternatives.add_solution!","text":"add_solution!(\n    problem::MetaheuristicProblem,\n    result::Metaheuristics.State,\n    metric::Distances.SemiMetric\n)\n\nModify a Metaheuristic problem representing the alternative generating problem for the original LP using a newly found alternative solution. This function can be used when one wants to iteratively run a metaheuristic to find alternative solutions one by one.\n\nArguments:\n\nproblem::MetaheuristicProblem: problem to be modified by adding a solution.\nresult::Metaheuristics.State: result containing the optimal solution to add to the objective function.\nmetric::Distances.SemiMetric: metric used to evaluate distance between alternatives.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#NearOptimalAlternatives.create_alternative_generating_problem!-Union{Tuple{N}, Tuple{T}, Tuple{JuMP.Model, Float64, Vector{JuMP.VariableRef}, AbstractArray{T, N}}} where {T<:Union{JuMP.VariableRef, JuMP.AffExpr}, N}","page":"Reference","title":"NearOptimalAlternatives.create_alternative_generating_problem!","text":"create_alternative_generating_problem!(\n  model::JuMP.Model,\n  optimality_gap::Float64,\n  fixed_variables::Vector{VariableRef},\n  variables::AbstractArray{T,N},\n  weights::Vector{Float64};\n  method::Symbol = :HSJ,\n  metric::Distances.SemiMetric = SqEuclidean(),\n) where {T<:Union{VariableRef,AffExpr},N}\n\nTransform a JuMP model into a model solving its corresponding modelling-for-generating-alternatives problem.\n\nArguments\n\nmodel::JuMP.Model: a solved JuMP model for which alternatives are generated.\noptimality_gap::Float64: the maximum percentage deviation (>= 0) an alternative may have compared to the optimal solution.\nfixed_variables::Vector{VariableRef}=[]: a subset of all variables of model that are not allowed to be changed when seeking for alternatives.\nvariables::AbstractArray{T,N}: the variables of model for which are considered when generating alternatives.\nweights::Vector{Float64}: a vector of weights used to update the objective function.\nmethod::Symbol = :HSJ: the method used to model the problem for generating alternatives.\nmetric::Distances.SemiMetric = SqEuclidean(): the metric used to maximise the difference between alternatives and the optimal solution.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#NearOptimalAlternatives.create_alternative_generating_problem-Tuple{JuMP.Model, Metaheuristics.Algorithm, OrderedCollections.OrderedDict{JuMP.VariableRef, Float64}, Float64, Distances.SemiMetric, Dict{MathOptInterface.VariableIndex, Float64}}","page":"Reference","title":"NearOptimalAlternatives.create_alternative_generating_problem","text":"problem = create_alternative_generating_problem(\n    model::JuMP.Model,\n    algorithm::Metaheuristics.Algorithm,\n    initial_solution::OrderedDict{VariableRef, Float64},\n    optimality_gap::Float64,\n    metric::Distances.SemiMetric,\n    fixed_variables::Dict{VariableRef, Float64}\n)\n\nCreate the Metaheuristic problem representing the alternative generating problem for the original LP.\n\nArguments:\n\nmodel::JuMP.Model: JuMP model representing the original LP.\nalgorithm::Metaheuristics.Algorithm: Metaheuristic algorithm to solve the alternative generating problem.\ninitial_solution::OrderedDict{VariableRef, Float64}: (near-)optimal solution to model, for which alternatives are sought.\noptimality_gap::Float64: maximum gap in objective value between initial_solution and alternative solutions.\nmetric::Distances.SemiMetric: distance metric used to compute distance between alternative solutions and initial_solution.\nfixed_variables::Dict{MOI.VariableIndex, Float64}: solution values for fixed variables of the original problem.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#NearOptimalAlternatives.create_objective-Tuple{JuMP.Model, OrderedCollections.OrderedDict{JuMP.VariableRef, Float64}, Float64, Distances.SemiMetric, Dict{Int64, Int64}, Dict{MathOptInterface.VariableIndex, Float64}}","page":"Reference","title":"NearOptimalAlternatives.create_objective","text":"objective = create_objective(\n    model::JuMP.Model,\n    solution::OrderedDict{JuMP.VariableRef, Float64},\n    optimality_gap::Float64,\n    metric::Distances.SemiMetric,\n    index_map::Dict{Int64, Int64},\n    fixed_variables::Dict{VariableRef, Float64}\n)\n\nCreate an objective function supported by Metaheuristics.jl for the alternative generating problem.\n\nArguments\n\nmodel::JuMP.Model: solved JuMP model of the original lp problem.\nsolution::OrderedDict{JuMP.VariableRef, Float64}: solution value of the original lp problem excluding fixed variables.\noptimality_gap::Float64: maximum difference between objective value of optimal solution and alternative solutions.\nmetric::Distances.SemiMetric: distance metric used to measure distance between solutions.\nindex_map::Dict{Int64, Int64}: dictionary mapping indices in the JuMP/MathOptInterface model to indices of x.\nfixed_variables::Dict{VariableRef, Float64}: dictionary containing the values of the fixed variables.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#NearOptimalAlternatives.extract_bounds-Tuple{JuMP.Model, Dict{Int64, Int64}}","page":"Reference","title":"NearOptimalAlternatives.extract_bounds","text":"bounds = extract_bounds(\n    model::JuMP.Model,\n    index_map::Dict{Int64, Int64}\n)\n\nTransform the bounds from a JuMP Model into a matrix of bounds readable by Metaheuristics.jl.\n\nArguments\n\nmodel::JuMP.Model: solved JuMP model of the original lp problem.\nindex_map::Dict{Int64, Int64}: dictionary mapping indices in the JuMP/MathOptInterface model to indices of x.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#NearOptimalAlternatives.extract_constraint-Tuple{MathOptInterface.ScalarAffineFunction, Vector{Float64}, Dict{Int64, Int64}, Dict{MathOptInterface.VariableIndex, Float64}}","page":"Reference","title":"NearOptimalAlternatives.extract_constraint","text":"constraint = extract_constraint(\n    constraint::MOI.ConstraintFunction,\n    x::Vector{Float64},\n    index_map::Dict{Int64, Int64},\n    fixed_variables::Dict{MOI.VariableIndex, Float64}\n)\n\nConvert a constraint from a MathOptInterface function into a julia function of x. Supports only ScalarAffineFunction and VariableIndex constraints.\n\nArguments\n\nconstraint::MOI.ConstraintFunction: constraint transform into a julia function.\nx::Vector{Float64}: a vector representing an individual in the metaheuristic population.\nindex_map::Dict{Int64, Int64}: a dictionary mapping indices in the MathOptInterface model to indices of x.\nfixed_variables::Dict{MOI.VariableIndex, Float64}: a dictionary containing the values of the fixed variables.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#NearOptimalAlternatives.extract_objective-Tuple{JuMP.AffExpr, Vector{Float64}, Dict{Int64, Int64}, Dict{MathOptInterface.VariableIndex, Float64}}","page":"Reference","title":"NearOptimalAlternatives.extract_objective","text":"objective = extract_objective(\n    objective::JuMP.AffExpr,\n    x::Vector{Float64},\n    index_map::Dict{Int64, Int64},\n    fixed_variables::Dict{MOI.VariableIndex, Float64}\n)\n\nConvert the objective from a MathOptInterface function into a julia function of x. Supports only linear single-objective functions.\n\nArguments\n\nobjective::JuMP.AffExpr: the objective function to transform into a julia function.\nx::Vector{Float64}: a vector representing an individual in the metaheuristic population.\nindex_map::Dict{Int64, Int64}: a dictionary mapping indices in the MathOptInterface model to indices of x.\nfixed_variables::Dict{MOI.VariableIndex, Float64}: a dictionary containing the values of the fixed variables.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#NearOptimalAlternatives.generate_alternatives_metaheuristics-Tuple{JuMP.Model, Float64, Int64, Metaheuristics.Algorithm}","page":"Reference","title":"NearOptimalAlternatives.generate_alternatives_metaheuristics","text":"result = generate_alternatives_metaheuristics(\n  model::JuMP.Model,\n  optimality_gap::Float64,\n  n_alternatives::Int64,\n  metaheuristic_algorithm::Metaheuristics.Algorithm;\n  metric::Distances.Metric = SqEuclidean(),\n  selected_variables::Vector{VariableRef} = []\n)\n\nGenerate n_alternatives solutions to model which are as distant from the optimum and each other, but with a maximum optimality_gap, using a metaheuristic algorithm.\n\nArguments\n\nmodel::JuMP.Model: a solved JuMP model for which alternatives are generated.\noptimality_gap::Float64: the maximum percentage deviation (>=0) an alternative may have compared to the optimal solution.\nn_alternatives: the number of alternative solutions sought.\nmetaheuristic_algorithm::Metaheuristics.Algorithm: algorithm used to search for alternative solutions.\nmetric::Distances.Metric=SqEuclidean(): the metric used to maximise the difference between alternatives and the optimal solution.\nfixed_variables::Vector{VariableRef}=[]: a subset of all variables of model that are not allowed to be changed when seeking for alternatives.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#NearOptimalAlternatives.generate_alternatives_optimization!-Union{Tuple{N}, Tuple{T}, Tuple{JuMP.Model, Float64, AbstractArray{T, N}, Int64}} where {T<:Union{JuMP.VariableRef, JuMP.AffExpr}, N}","page":"Reference","title":"NearOptimalAlternatives.generate_alternatives_optimization!","text":"results = generatealternativesoptimization!(   model::JuMP.Model,   optimalitygap::Float64,   variables::AbstractArray{T,N},   nalternatives::Int64;   modelingmethod::Symbol = :MaxDistance,   metric::Distances.SemiMetric = SqEuclidean(),   fixedvariables::Vector{VariableRef} = VariableRef[], ) where {T<:Union{VariableRef,AffExpr},N} Generate `nalternativessolutions tomodelwhich are as distant from the optimum and each other, but with a maximumoptimality_gap`, using optimization.\n\nArguments\n\nmodel::JuMP.Model: a solved JuMP model for which alternatives are generated.\noptimality_gap::Float64: the maximum percentage deviation (>=0) an alternative may have compared to the optimal solution.\nvariables::AbstractArray{T,N}: the variables of model for which are considered when generating alternatives.\nn_alternatives: the number of alternative solutions sought.\nmodeling_method::Symbol = :Max_Distance: the method used to model the problem for generating alternatives.\nmetric::Distances.Metric=SqEuclidean(): the metric used to maximise the difference between alternatives and the optimal solution.\nfixed_variables::Vector{VariableRef}=[]: a subset of all variables of model that are not allowed to be changed when seeking for alternatives.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#NearOptimalAlternatives.is_better_psoga-Union{Tuple{T}, Tuple{T, T, Matrix{Float64}, Int64, Bool}} where T<:Metaheuristics.xFgh_solution","page":"Reference","title":"NearOptimalAlternatives.is_better_psoga","text":"isbetterpsoga(     A::T,     B::T,     centroids::Vector{Any},     subpopa::Int64,     subpopb::Int64,     maximisetotal::Bool   ) where {T <: Metaheuristics.xFghsolution}\n\nCompare two solutions of the PSOGA algorithm with respect to their distance to the optimal solution and other alternatives.\n\nArguments\n\nA: solution in PSOGA to be compared.\nB: solution in PSOGA to be compared.\ncentroids::Vector{Any}: vector of centroids per subpopulation. A centroid is the average point of all solutions in a subpopulation.\nsubpop::Int64: index of the subpopulation solution A and B are in. Note that they are always in the same, since we only compare within subpopulations or with themselves.\nmaximise_total::Bool: if true, we maximise the sum of distances between a point and all centroids of other subpopulations, else we maximise the minimum distance between a point and the centroids of other subpopulations.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#NearOptimalAlternatives.run_alternative_generating_problem!-Tuple{NearOptimalAlternatives.MetaheuristicProblem}","page":"Reference","title":"NearOptimalAlternatives.run_alternative_generating_problem!","text":"result = run_alternative_generating_problem!(\n    problem::MetaheuristicProblem\n)\n\nOptimize the problem using the specified metaheuristic algorithm and return the result.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#NearOptimalAlternatives.update_objective_function!-Union{Tuple{N}, Tuple{T}, Tuple{JuMP.Model, AbstractArray{T, N}}} where {T<:Union{JuMP.VariableRef, JuMP.AffExpr}, N}","page":"Reference","title":"NearOptimalAlternatives.update_objective_function!","text":"update_objective_function!(\n    model::JuMP.Model,\n    variables::AbstractArray{T,N};\n    weights::Vector{Float64} = zeros(length(variables)),\n    method::Symbol = :HSJ,\n    metric::Distances.SemiMetric = SqEuclidean()) where {T<:Union{VariableRef,AffExpr},N}\n)\n\nAdd a previously found solution to a modelling-for-generating-alternatives problem. Used for iteratively finding multiple alternative solutions.\n\nArguments\n\nmodel::JuMP.Model: a solved JuMP model for which alternatives are generated.\nvariables::AbstractArray{T,N}: the variables of model for which are considered when generating alternatives.\nweights::Vector{Float64}: a vector of weights used to update the objective function.\nmethod::Symbol = :HSJ: the method used to model the problem for generating alternatives.\nmetric::Distances.SemiMetric = SqEuclidean(): the metric used to maximise the difference between alternatives and the optimal solution.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#NearOptimalAlternatives.update_solutions!-Tuple{NearOptimalAlternatives.AlternativeSolutions, JuMP.Model}","page":"Reference","title":"NearOptimalAlternatives.update_solutions!","text":"update_solutions!(results::AlternativeSolutions, model::JuMP.Model)\n\nUpdate the set of results AlternativeSolutions with the variable values obtained when solving the JuMP model model.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#NearOptimalAlternatives.update_solutions!-Tuple{NearOptimalAlternatives.AlternativeSolutions, Metaheuristics.State, OrderedCollections.OrderedDict{JuMP.VariableRef, Float64}, Dict{MathOptInterface.VariableIndex, Float64}, JuMP.Model}","page":"Reference","title":"NearOptimalAlternatives.update_solutions!","text":"update_solutions!(results::AlternativeSolutions, model::JuMP.Model)\n\nUpdate the set of results AlternativeSolutions with the variable values obtained when solving using Metaheuristics.\n\nArguments\n\nresults::AlternativeSolutions: set of solutions to add a new solution to.\nstate::Metaheuristics.State: contains results to metaheuristic solve.\ninitial:solution::OrderedDict{VariableRef, Float64}: used to identify the indices of the metaheuristic solution in the JuMP model.\nfixed_variables::Dict{MOI.VariableIndex, Float64}: set of fixed variables and their solution values.\nmodel::JuMP.Model: original model for which alternative solutions are found.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#NearOptimalAlternatives.update_solutions!-Tuple{NearOptimalAlternatives.AlternativeSolutions, Metaheuristics.State, Vector{Any}, OrderedCollections.OrderedDict{JuMP.VariableRef, Float64}, Dict{MathOptInterface.VariableIndex, Float64}, JuMP.Model}","page":"Reference","title":"NearOptimalAlternatives.update_solutions!","text":"update_solutions!(results::AlternativeSolutions, model::JuMP.Model)\n\nUpdate the set of results AlternativeSolutions with the variable values obtained when solving using PSOGA.\n\nArguments\n\nresults::AlternativeSolutions: set of solutions to add a new solution to.\nstate::Metaheuristics.State: contains results to metaheuristic solve.\nsubBest::Vector{Any}: contains the best results per subpopulation of PSOGA, which are the actual results of solving.\ninitial:solution::OrderedDict{VariableRef, Float64}: used to identify the indices of the metaheuristic solution in the JuMP model.\nfixed_variables::Dict{MOI.VariableIndex, Float64}: set of fixed variables and their solution values.\nmodel::JuMP.Model: original model for which alternative solutions are found.\n\n\n\n\n\n","category":"method"},{"location":"20-tutorials/","page":"Tutorials","title":"Tutorials","text":"Pages = [\"tutorials.md\"]\nDepth = 5","category":"section"},{"location":"20-tutorials/#Tutorials","page":"Tutorials","title":"Tutorials","text":"Here are three tutorials on how to use NearOptimalAlternatives.jl. The tutorials show how to generate alternatives using optimization, a metaheuristic algorithm and our metaheuristic PSOGA, respectively.","category":"section"},{"location":"20-tutorials/#Tutorial-1:-Generate-alternatives-using-optimization","page":"Tutorials","title":"Tutorial 1: Generate alternatives using optimization","text":"Given a solved JuMP model called model, one should first define the number of alternatives they want to generate and the maximum deviation in objective value compared to the optimal solution. For instance,\n\noptimality_gap = 0.5 # Objective value may deviate at most 50% from optimal solution.\nn_alternatives = 2\n\nNow, they can call the following function to generate alternatives\n\nalternatives = NearOptimalAlternatives.generate_alternatives_optimization!(model, optimality_gap, n_alternatives)\n\nIf you only want to change specific variables of a problem when generating alternatives, you can fix the other variables as follows. Suppose you are solving a problem for which the model contains 3 variables (x_1, x_2, x_3) and you want to fix x_2. You then simply create a vector of fixed variables and supply this as a parameter to the function.\n\nfixed_variables = [x_2] # x_2 should be the VariableRef in the JuMP model.\nalternatives = NearOptimalAlternatives.generate_alternatives(model, optimality_gap, n_alternatives, fixed_variables=fixed_variables)","category":"section"},{"location":"20-tutorials/#Tutorial-2:-Generate-alternatives-using-a-metaheuristic-algorithm-from-Metaheuristics.jl","page":"Tutorials","title":"Tutorial 2: Generate alternatives using a metaheuristic algorithm from Metaheuristics.jl","text":"Generating alternatives using a metaheuristic algorithm from Metaheuristics.jl works similarly. We still need a solved model, an optimality_gap and the amount of alternatives n_alternatives. As an extra, we now need to define the algorithm we want to use. For instance:\n\nmetaheuristic_algorithm = Metaheuristics.PSO()\n\nThen we call the following function using all parameters to obtain the results.\n\nalternatives = generate_alternatives(model, optimality_gap, n_alternatives, metaheuristic_algorithm)\n\nAs a default, this method uses the squared euclidean metric from the Distances.jl package. If you want to use a different distance metric, you can simply define the metric and supply it as an argument to the function as follows (weighted metrics are also supported).\n\nmetric = Distances.Euclidean() # Use Euclidean instead of SqEuclidean\nalternatives = NearOptimalAlternatives.generate_alternatives(model, optimality_gap, n_alternatives, metric=metric)\n\nAgain, fixed_variables can be supplied as optional parameters. The parameters of the metaheuristic_algorithm can be defined when initializing it. For more details on this, take a look at the Metaheuristics.jl documentation.","category":"section"},{"location":"20-tutorials/#Tutorial-3:-Generate-alternatives-using-PSOGA-from-this-package","page":"Tutorials","title":"Tutorial 3: Generate alternatives using PSOGA from this package","text":"To use our concurrent Particle Swarm optimization metaheuristic PSOGA, the same steps should be taken as when using another metaheuristic. The only difference is that you have to supply the number of alternatives to the algorithm as well, so it knows how many subpopulations it should keep in its parameters. The following code shows how to do this and obtain the alternatives.\n\nmetaheuristic_algorithm = NearOptimalAlternatives.PSOGA(N_solutions=n_alternatives)\nalternatives = generate_alternatives(model, optimality_gap, n_alternatives, metaheuristic_algorithm)","category":"section"},{"location":"90-contributing/#contributing","page":"Contributing guidelines","title":"Contributing guidelines","text":"First of all, thanks for the interest!\n\nWe welcome all kinds of contribution, including, but not limited to code, documentation, examples, configuration, issue creating, etc.\n\nBe polite and respectful, and follow the code of conduct.","category":"section"},{"location":"90-contributing/#Bug-reports-and-discussions","page":"Contributing guidelines","title":"Bug reports and discussions","text":"If you think you found a bug, feel free to open an issue. Focused suggestions and requests can also be opened as issues. Before opening a pull request, start an issue or a discussion on the topic, please.","category":"section"},{"location":"90-contributing/#Working-on-an-issue","page":"Contributing guidelines","title":"Working on an issue","text":"If you found an issue that interests you, comment on that issue what your plans are. If the solution to the issue is clear, you can immediately create a pull request (see below). Otherwise, say what your proposed solution is and wait for a discussion around it.\n\ntip: Tip\nFeel free to ping us after a few days if there are no responses.\n\nIf your solution involves code (or something that requires running the package locally), check the developer documentation. Otherwise, you can use the GitHub interface directly to create your pull request.","category":"section"},{"location":"#Welcome","page":"Welcome","title":"Welcome","text":"NearOptimalAlternatives.jl is a package for generating near optimal alternative solutions to a solved JuMP.jl optimization problem. The alternative solutions are within a maximum specified percentage of the optimum and are as different from the optimal solution (and other alternatives) as possible. Alternatives can either be generated using mathematical optimization or using a metaheuristic algorithm. For the latter, this package depends on Metaheuristics.jl.","category":"section"},{"location":"#License","page":"Welcome","title":"License","text":"This content is released under the Apache License 2.0 license.","category":"section"},{"location":"#Contributors","page":"Welcome","title":"Contributors","text":"<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->\n<!-- prettier-ignore-start -->\n<!-- markdownlint-disable -->\n<table>\n  <tbody>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/g-moralesespana\"><img src=\"https://avatars.githubusercontent.com/u/42405171?v=4?s=100\" width=\"100px;\" alt=\"Germán Morales\"/><br /><sub><b>Germán Morales</b></sub></a><br /><a href=\"#research-g-moralesespana\" title=\"Research\">🔬</a> <a href=\"#ideas-g-moralesespana\" title=\"Ideas, Planning, & Feedback\">🤔</a> <a href=\"#fundingFinding-g-moralesespana\" title=\"Funding Finding\">🔍</a> <a href=\"#projectManagement-g-moralesespana\" title=\"Project Management\">📆</a></td>\n    </tr>\n  </tbody>\n</table>\n\n<!-- markdownlint-restore -->\n<!-- prettier-ignore-end -->\n\n<!-- ALL-CONTRIBUTORS-LIST:END -->","category":"section"}]
}
